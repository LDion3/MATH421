---
title: "Midterm Project Presentation"
author: "Louis Dion"
date: "11/25/2019"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r}
#packages
library(tidyverse)
library(haven)
library(caret)
#bring in dataset from computer
hospital <- read_sas("C:/Users/student/Documents/MATH421/data/hdd0318cy.sas7bdat", NULL)
#only patients from 2015 to 2018
hospital1<-hospital%>%filter(yoa==c(15,16,17,18))
#make numeric variables for those that are supposed to be numeric 
for (i in c(37:38,41:54,57,67,69:70,72,74)){
  hospital1[[i]]=as.numeric(hospital1[[i]])
}
#make character variable for admission variables
hospital1$moa<-as.character(hospital1$moa)
hospital1$yoa<-as.character(hospital1$yoa)
#remove people with missing sex
hospital1<-hospital1%>%filter(sex==c(1,2))
#create "Expired" variable where 1 is person has expired or died and 0 is not.
hospital1$Expired[hospital1$dispub92==c(20,40,41,42)]<-'1'
hospital1$Expired[hospital1$dispub92!=c(20,40,41,42)]<-'0'
#create number of diagnoses varibles
for (i in 1:nrow(hospital1)) {
  hospital1$numdx[i]<-sum(hospital1[i,c(16:22,59:62,76:89)]!='')
}
#create number of prescriptions variable
for (i in 1:nrow(hospital1)) {
  hospital1$numpx[i]<-sum(hospital1[i,c(23:32,90:104)]!='')
}
```
## Dataset

- Rhode Island Hospital dataset
- Restricted to year 2015-2018
- Removed all observations with unknown sex
- Created "Expired" variable for whether a person died or not
- Create "numdx" and "numpx" showing number of diagnoses and number of prescriptions data has
```{r}
head(hospital1)
```


## Data Visualization

- Graph 1
```{r}
ggplot(hospital1,aes(x=provider,fill=provider))+
  geom_bar()
```

## Data Visualization

- Graph 2
```{r}
ggplot(hospital1,aes(x=tot))+
  geom_density()+
  xlim(0,150000)
```

## Data Visualization

- Graph 3
```{r}
ggplot(hospital1,aes(x=payer,fill=payer))+
  geom_bar()
```

## Data Visualization

- Graph 4
```{r}
ggplot(hospital1,aes(x=admtype,fill=admtype))+
  geom_bar()
```

## Data Visualization

- Graph 5
```{r}
ggplot(hospital1,aes(x=age))+
  geom_histogram(bins=20,fill='blue')
```

## Data Visualization

- Graph 6
```{r}
ggplot(hospital1%>%filter(er_mode==c(1,2,3,4,5)),aes(x=er_mode,fill=er_mode))+
  geom_bar()
```

## Data Visualization

- Graph 7
```{r}
ggplot(hospital1%>%filter(raceethn!=9&raceethn!=''),aes(x=raceethn,fill=raceethn))+
  geom_bar()
```

## Data Visualization

- Graph 8
```{r}
ggplot(hospital1,aes(x=age,fill=sex))+
  geom_density(position='dodge',alpha=0.5)
```

## Data Visualization

- Graph 9
```{r}
ggplot(hospital1%>%filter(admtype!=9),aes(x=admtype,y=tot,fill=sex))+
  geom_bar(stat='identity',position='dodge')
```

## Data Visualization

- Graph 10
```{r}
ggplot(hospital1%>%filter(raceethn!=9&raceethn!=''),aes(x=sex,y=raceethn,fill=age))+
  geom_tile()+
  facet_wrap(~Expired,(nrows=2))
```

## Predictive Modeling
- Prediction Variable: Expired
- Variable used for predicting: age, sex, race,admtype,trandb,tot, numdx, numpx
```{r}
modeldf<-hospital1%>%select(c(4,5,6,13,42,58,136:138))%>%filter(admtype!=9)
#make the target variable a factor variable
modeldf$Expired<-as.factor(modeldf$Expired)

#Splitting the data
set.seed(2019)
splitIndex <- createDataPartition(modeldf$Expired, p = .70, list = FALSE)
train <- modeldf[splitIndex,]
test <- modeldf[-splitIndex,]
#The expired variable is very imbalanced, so we are balacning the data before making the models.
train0 = train[train$Expired == '0',]
train1 = train[train$Expired == '1',]
n0 = nrow(train0)
n1 = nrow(train1)
train00 = train0[sample(1:n0, n1),]
train_under = rbind(train00, train1)
#use train_under and test for models
head(modeldf)
```
## Predictive Modeling
- Model 1: K-Nearest Neighbors
- Tuning parameters: k: Number of neighbors
```{r}
myGrid = expand.grid(k=c(1:15))

model <- train(Expired~.,data = train_under, method = "knn", tuneGrid = myGrid)

pred  = predict(model, test)
cm=confusionMatrix(pred, test$Expired, positive="1")
print(cm$byClass['Balanced Accuracy'])
```

## Predictive Modeling
- Model 2: Boosted Logistic Regression
- Tuning parameters: nIter: number of iterations
```{r}
myGrid = expand.grid(nIter=c(1:30))

model <- train(Expired~.,data = train_under, method = "LogitBoost", tuneGrid = myGrid)

pred  = predict(model, test)
cm=confusionMatrix(pred, test$Expired, positive="1")
print(cm$byClass['Balanced Accuracy'])
```

## Predictive Modeling
- Model 3: rpart2
- Tuning parameters: maxdepth
```{r}
myGrid = expand.grid(maxdepth=c(1:30))

model <- train(Expired~.,data = train_under, method = "rpart2", tuneGrid = myGrid)

pred  = predict(model, test)
cm=confusionMatrix(pred, test$Expired, positive="1")
print(cm$byClass['Balanced Accuracy'])

```

## Predictive Modeling
- Model 4: Ranger
- Tuning parameters: mtry, splitrule, min node size
```{r}
myGrid = expand.grid(mtry = c(1:10), splitrule = c("gini"), min.node.size = c(1:10))

model <- train(Expired~.,data = train_under, method = "ranger", tuneGrid = myGrid)

pred  = predict(model, test)
cm=confusionMatrix(pred, test$Expired, positive="1")
print(cm$byClass['Balanced Accuracy'])
```

## Predictive Modeling
- Model 5: Stepwise Linear Discriminant Analysis 
- Tuning parameters: maxvar, direction
```{r}
myGrid = expand.grid(maxvar=c(1:5),direction=c("both", "forward", "backward"))

model <- train(Expired~.,data = train_under, method = "stepLDA", tuneGrid = myGrid)

pred  = predict(model, test)
cm=confusionMatrix(pred, test$Expired, positive="1")
print(cm$byClass['Balanced Accuracy'])
```

## Balanced Accuracy Rankings
- #1: Ranger - .8391
- #2: rpart2 - 0.8224
- #3: Boosted Logistic Regression - 0.8221
- #4: stepLDA - 0.8161
- #5: K-Nearest Neighbors - 0.6531




